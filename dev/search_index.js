var documenterSearchIndex = {"docs":
[{"location":"#LVModels.jl-Documentation","page":"Home","title":"LVModels.jl Documentation","text":"","category":"section"},{"location":"#Neural-Differential-Equation-Model","page":"Home","title":"Neural Differential Equation Model","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":" LVModels.AbstractNDEModel\n LVModels.NDE","category":"page"},{"location":"#LVModels.AbstractNDEModel","page":"Home","title":"LVModels.AbstractNDEModel","text":"AbstractNDEModel\n\nSupertype of the neural differential equation model defined in this package.\n\n\n\n\n\n","category":"type"},{"location":"#LVModels.NDE","page":"Home","title":"LVModels.NDE","text":"NDE{P,R,A,K} <: AbstractNDEModel\n\nModel for setting up and training Neural Differential Equations.\n\nFields:\n\np: Parameter struct instance\nprob: DEProblem \nalg: Algorithm to use for the solve command \nkwargs: any additional keyword arguments that should be handed over (e.g. sensealg)\n\nConstructors\n\nNDE(prob; alg=Tsit5(), kwargs...)\nNDE(model::NDE; alg=model.alg, kwargs...) remake the model with different kwargs and solvers\n\nInput / call\n\nAn instance of the model is called with a trajectory pair (t,x) in t are the timesteps that NDE is integrated for and x is a trajectory N x ... x N_t in which x[:, ... , 1] is taken as the initial condition. \n\n\n\n\n\n","category":"type"},{"location":"#Training-Parameters","page":"Home","title":"Training Parameters","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":" LVModels.LearnableParams","category":"page"},{"location":"#LVModels.LearnableParams","page":"Home","title":"LVModels.LearnableParams","text":"mutable struct LearnableParams{T}\n\nLearnable parameters while training the model.\n\nFields:\n\nθ: Neural network weights\nθ1: Decay rates vector\n\nConstructor\n\nLearnableParams(θ, θ1)\n\n\n\n\n\n","category":"type"},{"location":"#Data-Manipulation","page":"Home","title":"Data Manipulation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":" LVModels.sparsify_data\n LVModels.get_mask_for_batch","category":"page"},{"location":"#LVModels.sparsify_data","page":"Home","title":"LVModels.sparsify_data","text":"sparsify_data(sol; fraction=1.0)\n\nRandomly sparsifies only the last dimension of the solution data from an n-dimensional system by masking a fraction of its values.\n\nArguments\n\nsol: A solution object containing the time array (sol.t) and state values.\nfraction: The probability (between 0 and 1) of keeping a data point unmasked in the last dimension. Default is 1.0 (no sparsification).\n\nReturns\n\nA tuple (t, X_sparse, mask), where:\n\nt: The time array from the solution.\nX_sparse: The sparsified state data array, where only the last dimension is masked.\nmask: A binary mask array applied to the last dimension, indicating retained (1) and masked (0) values.\n\n\n\n\n\n","category":"function"},{"location":"#LVModels.get_mask_for_batch","page":"Home","title":"LVModels.get_mask_for_batch","text":"get_mask_for_batch(batch_t, global_mask, t0, dt)\n\nExtracts a slice of the global mask corresponding to a given batch time vector.\n\nArguments\n\nbatch_t: A vector of time points for the current batch.\nglobal_mask: A binary mask array corresponding to the full time series.\nt0: The starting time of the global time series.\ndt: The time step interval between consecutive points in the global time series.\n\nReturns\n\nA mask slice corresponding to the time points in batch_t, extracted from global_mask.\n\n\n\n\n\n","category":"function"},{"location":"#Loss-Function","page":"Home","title":"Loss Function","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":" LVModels.loss","category":"page"},{"location":"#LVModels.loss","page":"Home","title":"LVModels.loss","text":"loss(m, batch, truth, batch_mask; λ1=0f0, λ2=0f0)\n\nComputes the loss for an n-dimensional system based on predicted values, ground truth, and a mask for the batch. The loss consists of mean squared errors (MSE) for each dimension, along with regularization terms for model parameters.\n\nArguments\n\nm: A model producing predictions for each dimension of the system.\nbatch: The input data batch to the model.\ntruth: The ground truth values for the n-dimensional system.\nbatch_mask: A mask that is applied to the batch to handle missing or masked data points.\nλ1: The weight for the L1 regularization term (default is 0).\nλ2: The weight for the L2 regularization term (default is 0).\n\nReturns\n\nThe total loss, which is the sum of:\n\nMean squared error (MSE) for each dimension (x, y, ..., n),\nL1 regularization of model parameters (if λ1 > 0),\nL2 regularization of model parameters (if λ2 > 0).\n\n\n\n\n\n","category":"function"},{"location":"#Model-Performance-Evaluation","page":"Home","title":"Model Performance Evaluation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":" LVModels.plot_model_performance","category":"page"},{"location":"#LVModels.plot_model_performance","page":"Home","title":"LVModels.plot_model_performance","text":"plot_model_performance(sol, t, X_sparse, train_70, model, U_re, U_truth, mask, dt)\n\nGenerates and returns four plots to evaluate model performance of an n-dimensional system:\n\nTrajectories Plot: Compares predicted trajectories with ground truth for all dimensions (first 70 points).\nInteraction Terms Plot: Compares neural network outputs with expected interaction terms (first 70 points).\nL2 Error Plot: Computes and visualizes the total L2 error across all dimensions at each time step (first 70 points).\nReconstructed Solution Plot: Compares the full ground truth trajectory with NODE predictions over all time points.\n\nArguments\n\nsol: Original solution object.\nt: The time vector associated with the original solution object.\nX_sparse: The sparsified ground truth.\ntrain_70: Training data batches of size 70. \nmodel: The trained model used to predict system trajectories.\nU_re: A function that reconstructs interaction terms from the ANN parameters.\nU_truth: True interaction terms.\nmask: The global mask used to indicate available data points.\ndt: Time step interval between consecutive points.\n\nReturns\n\nA tuple containing four plots:\n\nplt_traj: The trajectories plot (first 70 points).\nplt_interaction: The interaction terms plot (first 70 points).\nplt_l2_error: The L2 error plot (first 70 points).\nplt_re: The reconstructed solution plot (full time range).\n\n\n\n\n\n","category":"function"},{"location":"#Symbolic-Regression","page":"Home","title":"Symbolic Regression","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":" LVModels.perform_symbolic_regression","category":"page"},{"location":"#LVModels.perform_symbolic_regression","page":"Home","title":"LVModels.perform_symbolic_regression","text":"perform_symbolic_regression(X_sparse, dx, niterations=100; binary_operators=[+, *, -], unary_operators=[])\n\nPerform symbolic regression to extract interpretable equations from a neural ODE model.\n\nArguments\n\nX_sparse: Input features for regression.\ndx: The learned interaction terms from the neural ODE model.\nniterations: Number of iterations for the symbolic regression search (default=100).\nbinary_operators: List of binary operators to use in equation search (default [+, *, -]).\nunary_operators: List of unary operators to use in equation search (default []).\n\nReturns\n\nhall_of_fame: Best equations found for each dimension.\npareto_frontiers: Pareto-optimal equations for each dimension.\n\n\n\n\n\n","category":"function"}]
}
